{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "--describe your project at a high level--\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Explain what you plan to do in the project in more detail. What data do you use? What is your end solution look like? What tools did you use? etc>\n",
    "\n",
    "#### Describe and Gather Data \n",
    "Describe the data sets you're using. Where did it come from? What type of information is included? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"AWS Spark Processes Ran Locally\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dataframe for the demographics data\n",
    "us_demographics_path = \"us-cities-demographics.csv\"\n",
    "demographics = spark.read.csv(us_demographics_path, sep=\";\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Median Age: string (nullable = true)\n",
      " |-- Male Population: string (nullable = true)\n",
      " |-- Female Population: string (nullable = true)\n",
      " |-- Total Population: string (nullable = true)\n",
      " |-- Number of Veterans: string (nullable = true)\n",
      " |-- Foreign-born: string (nullable = true)\n",
      " |-- Average Household Size: string (nullable = true)\n",
      " |-- State Code: string (nullable = true)\n",
      " |-- Race: string (nullable = true)\n",
      " |-- Count: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Listing the schema for the demographics data\n",
    "demographics.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------------+\n",
      "|      City|  State|                Race|\n",
      "+----------+-------+--------------------+\n",
      "|Birmingham|Alabama|Black or African-...|\n",
      "|Birmingham|Alabama|American Indian a...|\n",
      "|Birmingham|Alabama|               Asian|\n",
      "|Birmingham|Alabama|  Hispanic or Latino|\n",
      "|Birmingham|Alabama|               White|\n",
      "|    Dothan|Alabama|               Asian|\n",
      "|    Dothan|Alabama|               White|\n",
      "|    Dothan|Alabama|  Hispanic or Latino|\n",
      "|    Dothan|Alabama|Black or African-...|\n",
      "|    Dothan|Alabama|American Indian a...|\n",
      "|    Hoover|Alabama|  Hispanic or Latino|\n",
      "|    Hoover|Alabama|               White|\n",
      "|    Hoover|Alabama|Black or African-...|\n",
      "|    Hoover|Alabama|               Asian|\n",
      "|Huntsville|Alabama|Black or African-...|\n",
      "|Huntsville|Alabama|               Asian|\n",
      "|Huntsville|Alabama|               White|\n",
      "|Huntsville|Alabama|  Hispanic or Latino|\n",
      "|Huntsville|Alabama|American Indian a...|\n",
      "|    Mobile|Alabama|               White|\n",
      "+----------+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring data\n",
    "demographics.select(['City', 'State', 'Race']).distinct().sort(['State', 'City']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+----------------------+\n",
      "|            City|     State|Average Household Size|\n",
      "+----------------+----------+----------------------+\n",
      "|       Brentwood|  New York|                  4.98|\n",
      "|          Perris|California|                  4.78|\n",
      "|       Santa Ana|California|                  4.58|\n",
      "| Florence-Graham|California|                  4.57|\n",
      "|         Lynwood|California|                  4.43|\n",
      "|         Fontana|California|                  4.15|\n",
      "|    Baldwin Park|California|                  4.13|\n",
      "|          Oxnard|California|                  4.08|\n",
      "|         Compton|California|                  4.08|\n",
      "|      South Gate|California|                  3.97|\n",
      "|       Poinciana|   Florida|                  3.93|\n",
      "|   Moreno Valley|California|                   3.9|\n",
      "|          Cicero|  Illinois|                  3.89|\n",
      "|         Norwalk|California|                  3.88|\n",
      "|   Jurupa Valley|California|                  3.87|\n",
      "|          Rialto|California|                  3.83|\n",
      "|     Santa Maria|California|                  3.83|\n",
      "|West Valley City|      Utah|                  3.81|\n",
      "|   Miami Gardens|   Florida|                  3.75|\n",
      "|East Los Angeles|California|                  3.75|\n",
      "+----------------+----------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Exploring data for white people\n",
    "# Using filter/where\n",
    "# household size is the same for all races\n",
    "demographics.select(['City','State','Average Household Size']).filter(demographics.Race == 'White').sort('Average Household Size', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+----------------------+\n",
      "|           City|     State|Average Household Size|\n",
      "+---------------+----------+----------------------+\n",
      "|      Brentwood|  New York|                  4.98|\n",
      "|      Brentwood|  New York|                  4.98|\n",
      "|      Brentwood|  New York|                  4.98|\n",
      "|      Brentwood|  New York|                  4.98|\n",
      "|      Brentwood|  New York|                  4.98|\n",
      "|         Perris|California|                  4.78|\n",
      "|         Perris|California|                  4.78|\n",
      "|         Perris|California|                  4.78|\n",
      "|         Perris|California|                  4.78|\n",
      "|      Santa Ana|California|                  4.58|\n",
      "|      Santa Ana|California|                  4.58|\n",
      "|      Santa Ana|California|                  4.58|\n",
      "|      Santa Ana|California|                  4.58|\n",
      "|      Santa Ana|California|                  4.58|\n",
      "|Florence-Graham|California|                  4.57|\n",
      "|Florence-Graham|California|                  4.57|\n",
      "|Florence-Graham|California|                  4.57|\n",
      "|        Lynwood|California|                  4.43|\n",
      "|        Lynwood|California|                  4.43|\n",
      "|        Lynwood|California|                  4.43|\n",
      "+---------------+----------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.select(['City','State','Average Household Size']).sort('Average Household Size', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+---------------+-----------------+------+--------------------+------------+----------------------+\n",
      "|           City|     State|Male Population|Female Population| Count|                Race|Foreign-born|Average Household Size|\n",
      "+---------------+----------+---------------+-----------------+------+--------------------+------------+----------------------+\n",
      "|      Brentwood|  New York|          31395|            32397| 46347|               White|       27058|                  4.98|\n",
      "|      Brentwood|  New York|          31395|            32397|  4242|American Indian a...|       27058|                  4.98|\n",
      "|      Brentwood|  New York|          31395|            32397|  8619|Black or African-...|       27058|                  4.98|\n",
      "|      Brentwood|  New York|          31395|            32397| 40111|  Hispanic or Latino|       27058|                  4.98|\n",
      "|      Brentwood|  New York|          31395|            32397|  1647|               Asian|       27058|                  4.98|\n",
      "|         Perris|California|          41623|            33336| 23882|               White|       23277|                  4.78|\n",
      "|         Perris|California|          41623|            33336| 54398|  Hispanic or Latino|       23277|                  4.78|\n",
      "|         Perris|California|          41623|            33336|  9393|Black or African-...|       23277|                  4.78|\n",
      "|         Perris|California|          41623|            33336|  3341|               Asian|       23277|                  4.78|\n",
      "|      Santa Ana|California|         167503|           167920|  5813|Black or African-...|      152999|                  4.58|\n",
      "|      Santa Ana|California|         167503|           167920| 37651|               Asian|      152999|                  4.58|\n",
      "|      Santa Ana|California|         167503|           167920|  4838|American Indian a...|      152999|                  4.58|\n",
      "|      Santa Ana|California|         167503|           167920|262436|  Hispanic or Latino|      152999|                  4.58|\n",
      "|      Santa Ana|California|         167503|           167920|163096|               White|      152999|                  4.58|\n",
      "|Florence-Graham|California|          34186|            32173| 30591|               White|       28696|                  4.57|\n",
      "|Florence-Graham|California|          34186|            32173|  5060|Black or African-...|       28696|                  4.57|\n",
      "|Florence-Graham|California|          34186|            32173| 60895|  Hispanic or Latino|       28696|                  4.57|\n",
      "|        Lynwood|California|          35634|            36371|   994|               Asian|       28061|                  4.43|\n",
      "|        Lynwood|California|          35634|            36371|  5346|Black or African-...|       28061|                  4.43|\n",
      "|        Lynwood|California|          35634|            36371| 48670|               White|       28061|                  4.43|\n",
      "+---------------+----------+---------------+-----------------+------+--------------------+------------+----------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics.select(['City','State', 'Male Population','Female Population', 'Count', 'Race' ,'Foreign-born','Average Household Size']).sort('Average Household Size', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Race='Black or African-American'),\n",
       " Row(Race='Hispanic or Latino'),\n",
       " Row(Race='White'),\n",
       " Row(Race='Asian'),\n",
       " Row(Race='American Indian and Alaska Native')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.select('Race').distinct().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_data_path = \"immigration_data_sample.csv\"\n",
    "country_codes_path = \"country_codes.csv\"\n",
    "immigrants = spark.read.csv(immigration_data_path, header=True)\n",
    "countries = spark.read.csv(country_codes_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "PythonException",
     "evalue": "\n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 449, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/cloudpickle/cloudpickle.py\", line 562, in subimport\n    __import__(name)\nModuleNotFoundError: No module named 'pandas'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-99d09ec9d66f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mconvert_to_datetime_udf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert_to_datetime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDateType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfact_immigration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimmigrants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrival_date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_to_datetime_udf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrdate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mfact_immigration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'arrdate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'arrival_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate, vertical)\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvertical\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1308\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1310\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 603, in main\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 449, in read_udfs\n    udfs.append(read_single_udf(pickleSer, infile, eval_type, runner_conf, udf_index=i))\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 251, in read_single_udf\n    f, return_type = read_command(pickleSer, infile)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 71, in read_command\n    command = serializer._read_with_length(file)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 160, in _read_with_length\n    return self.loads(obj)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 430, in loads\n    return pickle.loads(obj, encoding=encoding)\n  File \"/anaconda3/lib/python3.7/site-packages/pyspark/python/lib/pyspark.zip/pyspark/cloudpickle/cloudpickle.py\", line 562, in subimport\n    __import__(name)\nModuleNotFoundError: No module named 'pandas'\n"
     ]
    }
   ],
   "source": [
    "#immigrants.select('arrdate').show()\n",
    "\n",
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import DateType\n",
    "import pandas as pd\n",
    "\n",
    "def convert_to_datetime(date):\n",
    "    \"\"\"\n",
    "    Convert to yyyy-mm-dd format\n",
    "    \n",
    "    :return: date in yyyy-mm-dd format\n",
    "    \"\"\"   \n",
    "    if date is not None:\n",
    "        return pd.Timestamp('1960-1-1')+pd.to_timedelta(date, unit='D')\n",
    "        \n",
    "convert_to_datetime_udf = udf(convert_to_datetime, DateType())\n",
    "fact_immigration = immigrants.withColumn('arrival_date', convert_to_datetime_udf(col('arrdate')))\n",
    "fact_immigration.select(['arrdate', 'arrival_date']).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- cicid: string (nullable = true)\n",
      " |-- i94yr: string (nullable = true)\n",
      " |-- i94mon: string (nullable = true)\n",
      " |-- i94cit: string (nullable = true)\n",
      " |-- i94res: string (nullable = true)\n",
      " |-- i94port: string (nullable = true)\n",
      " |-- arrdate: string (nullable = true)\n",
      " |-- i94mode: string (nullable = true)\n",
      " |-- i94addr: string (nullable = true)\n",
      " |-- depdate: string (nullable = true)\n",
      " |-- i94bir: string (nullable = true)\n",
      " |-- i94visa: string (nullable = true)\n",
      " |-- count: string (nullable = true)\n",
      " |-- dtadfile: string (nullable = true)\n",
      " |-- visapost: string (nullable = true)\n",
      " |-- occup: string (nullable = true)\n",
      " |-- entdepa: string (nullable = true)\n",
      " |-- entdepd: string (nullable = true)\n",
      " |-- entdepu: string (nullable = true)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: string (nullable = true)\n",
      " |-- dtaddto: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- insnum: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: string (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# printing the schemas for immigrants table\n",
    "# i94cit = Country Citizenship\n",
    "# i94res = Country Residence\n",
    "\n",
    "immigrants.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94mode|count|\n",
      "+-------+-----+\n",
      "|    1.0|  962|\n",
      "|    2.0|   10|\n",
      "|    3.0|   26|\n",
      "|    9.0|    2|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counts of immigrants via different modes\n",
    "immigrants.select([immigrants.i94mode]).groupBy(immigrants.i94mode).count().sort(immigrants.i94mode).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'CAST(country_code AS INT)'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# casting to a different type\n",
    "immigrants.i94res.cast(\"int\")\n",
    "countries.country_code.cast(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------+\n",
      "|count|       country|\n",
      "+-----+--------------+\n",
      "|  119|UNITED KINGDOM|\n",
      "|   79|         JAPAN|\n",
      "|   58|MEXICO Air Sea|\n",
      "|   54|         CHINA|\n",
      "|   52|       GERMANY|\n",
      "|   51|     AUSTRALIA|\n",
      "|   48|        FRANCE|\n",
      "|   37|   SOUTH KOREA|\n",
      "|   37|        BRAZIL|\n",
      "|   34|         INDIA|\n",
      "|   33|   NETHERLANDS|\n",
      "|   22|    ARGENTINA |\n",
      "|   19|      COLOMBIA|\n",
      "|   19|        SWEDEN|\n",
      "|   16|        TAIWAN|\n",
      "|   16|        ISRAEL|\n",
      "|   14|         ITALY|\n",
      "|   14|   SWITZERLAND|\n",
      "|   13|       IRELAND|\n",
      "|   13|     VENEZUELA|\n",
      "+-----+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What nationalities come to the US the most\n",
    "immigrants.groupBy(immigrants.i94res).count() \\\n",
    "            .join(countries, immigrants.i94res.cast(\"int\") == countries.country_code.cast(\"int\"), 'inner') \\\n",
    "            .select('count',countries.country) \\\n",
    "            .sort('count', ascending=False) \\\n",
    "            .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94visa|count|\n",
      "+-------+-----+\n",
      "|    1.0|  155|\n",
      "|    2.0|  831|\n",
      "|    3.0|   14|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Counts on the types of immigrants\n",
    "immigrants.select(immigrants.i94visa).groupBy(immigrants.i94visa).count().sort(immigrants.i94visa).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|     FL|  176|\n",
      "|     NY|  148|\n",
      "|     CA|  126|\n",
      "|   null|   53|\n",
      "|     HI|   51|\n",
      "|     TX|   29|\n",
      "|     GU|   27|\n",
      "|     NV|   26|\n",
      "|     IL|   24|\n",
      "|     MA|   17|\n",
      "|     NJ|   15|\n",
      "|     GA|   14|\n",
      "|     WA|   12|\n",
      "|     NE|   10|\n",
      "|     VA|   10|\n",
      "|     DC|    9|\n",
      "|     MD|    7|\n",
      "|     LA|    7|\n",
      "|     NC|    7|\n",
      "|     CT|    6|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What are the most popular destinations for immigrants to visit\n",
    "immigrants.select([immigrants.i94addr]).filter(immigrants.i94visa == 2).groupBy(immigrants.i94addr).count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|i94addr|count|\n",
      "+-------+-----+\n",
      "|     CA|   33|\n",
      "|     NY|   13|\n",
      "|     TX|   11|\n",
      "|     FL|   11|\n",
      "|     NV|    8|\n",
      "|     MA|    7|\n",
      "|     IL|    7|\n",
      "|     WA|    6|\n",
      "|     GA|    5|\n",
      "|   null|    5|\n",
      "|     PA|    4|\n",
      "|     NJ|    4|\n",
      "|     MI|    4|\n",
      "|     DC|    3|\n",
      "|     AZ|    3|\n",
      "|     MD|    3|\n",
      "|     TN|    3|\n",
      "|     SC|    2|\n",
      "|     MN|    2|\n",
      "|     VA|    2|\n",
      "+-------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What are the most popular destinations for immigrants to work at\n",
    "immigrants.select([immigrants.i94addr]).filter(immigrants.i94visa == 1).groupBy(immigrants.i94addr).count().sort('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n",
    "#### Cleaning Steps\n",
    "Document steps necessary to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform quality checks here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "* Propose how often the data should be updated and why.\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " * The database needed to be accessed by 100+ people."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "398dc28c06ad810e77de546bbdfa897a6ee0b83e59a5207339dda01a7843e01d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
